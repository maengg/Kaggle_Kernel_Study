{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Porto \bstacking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqeXMeWuW8JUG4Lng3FpaJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maengg/Kaggle_Kernel_Study/blob/main/Porto_%08stacking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_ZE2mighMkk",
        "outputId": "b3408d56-7643-47af-c157-a2f7e24ba81d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import gc\n",
        "\n",
        "print('loading files...')\n",
        "train = pd.read_csv('/content/drive/MyDrive/train.csv', na_values=-1)\n",
        "test = pd.read_csv('/content/drive/MyDrive/test.csv', na_values=-1)\n",
        "col_to_drop = train.columns[train.columns.str.startswith('ps_calc_')]\n",
        "train = train.drop(col_to_drop, axis=1)  \n",
        "test = test.drop(col_to_drop, axis=1)  \n",
        "\n",
        "for c in train.select_dtypes(include=['float64']).columns:\n",
        "    train[c]=train[c].astype(np.float32)\n",
        "    test[c]=test[c].astype(np.float32)\n",
        "for c in train.select_dtypes(include=['int64']).columns[2:]:\n",
        "    train[c]=train[c].astype(np.int8)\n",
        "    test[c]=test[c].astype(np.int8)    \n",
        "\n",
        "print(train.shape, test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk_GUYalhaTx",
        "outputId": "37d78fc2-ea76-4267-f771-f5a3842d45df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading files...\n",
            "(595212, 39) (892816, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gini(y, pred):\n",
        "    g = np.asarray(np.c_[y, pred, np.arange(len(y)) ], dtype=np.float)\n",
        "    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n",
        "    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n",
        "    gs -= (len(y) + 1) / 2.\n",
        "    return gs / len(y)\n",
        "\n",
        "def gini_xgb(pred, y):\n",
        "    y = y.get_label()\n",
        "    return 'gini', gini(y, pred) / gini(y, y)\n",
        "\n",
        "def gini_lgb(preds, dtrain):\n",
        "    y = list(dtrain.get_label())\n",
        "    score = gini(y, preds) / gini(y, y)\n",
        "    return 'gini', score, True"
      ],
      "metadata": {
        "id": "gV1YIADOiWYm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# xgb\n",
        "params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, \n",
        "          'objective': 'binary:logistic', 'eval_metric': 'auc', 'silent': True}\n",
        "\n",
        "X = train.drop(['id','target'], axis=1)\n",
        "features = X.columns\n",
        "X = X.values\n",
        "y = train['target'].values\n",
        "sub = test['id'].to_frame()\n",
        "sub['target'] = 0\n",
        "\n",
        "nrounds=200\n",
        "kfold=2\n",
        "# data가 불균형하기 때문에, 0과 1의 비율이 유지된 상태로 Fold를 나눠준다 -> StratifiedKFold\n",
        "skf = StratifiedKFold(n_split=kfold, random_state=0)\n",
        "for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
        "   print(' xgb kfold: {}  of  {} : '.format(i+1, kfold))\n",
        "   X_train, X_valid = X[train_index], X[valid_index]\n",
        "   y_train, y_valid = y[train_index], y[valid_index]\n",
        "   # DMatrix => 학습할때 더 빠르게 하기 위함.\n",
        "   d_train = xgb.DMatrix(X_train, y_train)\n",
        "   d_valid = xgb.DMatrix(X_valid, y_valid)\n",
        "   # 학습이 잘되는지 확인하면서 stop하기 위함. 즉, early stopping의 기준.\n",
        "   watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
        "   xgb_model = xgb.train(params, d_train, nrounds, watchlist, early_stopping_rounds=100,\n",
        "                         feval=gini_xgb, maximize=True, verbose_eval=100)\n",
        "   # ntree_limit => best round에서 +50까지만 예측해라 하고 4로 나눔. (lgb도 해서)\n",
        "   # 즉, xgb 2개 fold 나눠서 모델 2개로 sub의 0.5 채운 것.\n",
        "   sub['target'] +=xgb_model.predict(xgb.DMatrix(test[features].values),\n",
        "                                     ntree_limit=xgb.model.best_ntree_limit+50) / (2*kfold)\n",
        "gc.collect()\n",
        "sub.head(2)\n",
        "\n",
        "   # lgb\n",
        "params = {'metric': 'auc', 'learning_rate' : 0.01, 'max_depth':10, 'max_bin':10,  'objective': 'binary', \n",
        "          'feature_fraction': 0.8,'bagging_fraction':0.9,'bagging_freq':10,  'min_data': 500}\n",
        "\n",
        "skf = StratifiedKFold(n_splits=kfold, random_state=1)\n",
        "for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
        "    print(' lgb kfold: {}  of  {} : '.format(i+1, kfold))\n",
        "    X_train, X_eval = X[train_index], X[valid_index]\n",
        "    y_train, y_eval = y[train_index], y[valid_index]\n",
        "    lgb_model = lgb.train(params, lgb.Dataset(X_train, label=y_train), nrounds, \n",
        "                  lgb.Dataset(X_eval, label=y_eval), verbose_eval=100, \n",
        "                  feval=gini_lgb, early_stopping_rounds=100)\n",
        "    sub['target'] += lgb_model.predict(test[features].values, \n",
        "                        num_iteration=lgb_model.best_iteration) / (2*kfold)\n",
        "    \n",
        "sub.to_csv('sub10.csv', index=False, float_format='%.5f') \n",
        "gc.collect()\n",
        "sub.head(2)\n"
      ],
      "metadata": {
        "id": "VmQNUI9niXj1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
